{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spaCy Performance on Named Entity Recognition with Code-Mixed Data\n",
    "\n",
    "In this notebook we examine the multi-functional model spaCy's performances on named entity recognition (NER) tasks, when the data are multilingual. More specifically, we will be focusing on code-mixing (code-switched) data, where the vocabulary of two different languages are used interchangeably in one sentence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import spacy\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in file\n",
    "file_path = \"../data/train.conll\"\n",
    "\n",
    "# empty list to store DataFrames for each sentence\n",
    "corpus = []\n",
    "\n",
    "# read the CoNLL-U file line by line\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "    current_sentence = []\n",
    "    columns = [\"word\", \"lang\", \"entity_type\"]\n",
    "    for line in lines:\n",
    "        if line.startswith(\"# sent_enum\"):\n",
    "            # if a new sentence begins, process the current one\n",
    "            if current_sentence:\n",
    "                df = pd.DataFrame(current_sentence, columns=columns)\n",
    "                corpus.append(df)\n",
    "                current_sentence = []\n",
    "        else:\n",
    "            # append each line to the current sentence\n",
    "            current_sentence.append(line.strip().split(\"\\t\"))\n",
    "\n",
    "# last sentence in the file\n",
    "if current_sentence:\n",
    "    df = pd.DataFrame(current_sentence, columns=columns)\n",
    "    corpus.append(df)\n",
    "# each sentence cann now be called by corpus[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load spaCy model for both L1 and L2\n",
    "model_eng = spacy.load(\"en_core_web_sm\")\n",
    "model_spa = spacy.load(\"es_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_eng_sent(model_eng, corpus, sent_idx):\n",
    "    \"\"\"tag a sentence with English as L1\n",
    "    return a dictionary with language tags, gold NE tags and spacy NER results\"\"\"\n",
    "    sent_df = corpus[sent_idx][:-1]  # remove last row resulted by CoNLL-U seperator\n",
    "\n",
    "    # extract all pre-processed tokens to a list\n",
    "    gold_tokens = list(sent_df[\"word\"])\n",
    "    # regularize gold NER tags, save to list\n",
    "    gold_tags = [\"Yes\" if tag != \"O\" else \"O\" for tag in list(sent_df[\"entity_type\"])]\n",
    "    # also save language tags\n",
    "    gold_langs = list(sent_df[\"lang\"])\n",
    "\n",
    "    sentence_text = sent_df[\"word\"].str.cat(sep=\" \")\n",
    "    doc = model_eng(sentence_text)\n",
    "    nes = [i.text for i in doc.ents]\n",
    "    # flat the nes tokens\n",
    "    nes_tokens = [\n",
    "        item for sublist in [item.split() for item in nes] for item in sublist\n",
    "    ]\n",
    "\n",
    "    if len(nes_tokens) == 0:  # check if spaCy found any NE\n",
    "        spacy_tags = [\"O\"] * len(sent_df)\n",
    "    else:\n",
    "        spacy_tags = []  # list to store spaCy NER results\n",
    "        for token in gold_tokens:\n",
    "            if len(nes_tokens) != 0:\n",
    "                if token in nes_tokens[0] or nes_tokens[0] in token:\n",
    "                    spacy_tags.append(\"Yes\")\n",
    "                    nes_tokens = nes_tokens[1:]\n",
    "                else:\n",
    "                    spacy_tags.append(\"O\")\n",
    "            else:\n",
    "                spacy_tags.append(\"O\")\n",
    "\n",
    "    results = {\n",
    "        \"mlang\": \"eng\",\n",
    "        \"lang\": gold_langs,\n",
    "        \"true_ne\": gold_tags,\n",
    "        \"spacy_ne\": spacy_tags,\n",
    "    }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_spa_sent(model_spa, corpus, sent_idx):\n",
    "    \"\"\"tag a sentence with English as L1\n",
    "    return a dictionary with language tags, gold NE tags and spacy NER results\"\"\"\n",
    "    sent_df = corpus[sent_idx][:-1]  # remove last row resulted by CoNLL-U seperator\n",
    "\n",
    "    # extract all pre-processed tokens to a list\n",
    "    gold_tokens = list(sent_df[\"word\"])\n",
    "    # regularize gold NER tags, save to list\n",
    "    gold_tags = [\"Yes\" if tag != \"O\" else \"O\" for tag in list(sent_df[\"entity_type\"])]\n",
    "    # also save language tags\n",
    "    gold_langs = list(sent_df[\"lang\"])\n",
    "\n",
    "    sentence_text = sent_df[\"word\"].str.cat(sep=\" \")\n",
    "    doc = model_spa(sentence_text)\n",
    "    nes = [i.text for i in doc.ents]\n",
    "    # flat the nes tokens\n",
    "    nes_tokens = [\n",
    "        item for sublist in [item.split() for item in nes] for item in sublist\n",
    "    ]\n",
    "\n",
    "    if len(nes_tokens) == 0:  # check if spaCy found any NE\n",
    "        spacy_tags = [\"O\"] * len(sent_df)\n",
    "    else:\n",
    "        spacy_tags = []  # list to store spaCy NER results\n",
    "        for token in gold_tokens:\n",
    "            if len(nes_tokens) != 0:\n",
    "                if token in nes_tokens[0] or nes_tokens[0] in token:\n",
    "                    spacy_tags.append(\"Yes\")\n",
    "                    nes_tokens = nes_tokens[1:]\n",
    "                else:\n",
    "                    spacy_tags.append(\"O\")\n",
    "            else:\n",
    "                spacy_tags.append(\"O\")\n",
    "\n",
    "    results = {\n",
    "        \"mlang\": \"spa\",\n",
    "        \"lang\": gold_langs,\n",
    "        \"true_ne\": gold_tags,\n",
    "        \"spacy_ne\": spacy_tags,\n",
    "    }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def most_frequent_element(lst):\n",
    "#     most_frequent = max(set(lst), key=lst.count)\n",
    "#\n",
    "#     return most_frequent\n",
    "#\n",
    "#\n",
    "# ner_results = []\n",
    "# for i in tqdm(range(len(corpus)), desc=\"Processing\"):\n",
    "#     lang_tags = list(corpus[i][\"lang\"])\n",
    "#     # make sure the sentence is code-mixed\n",
    "#     if \"lang1\" in lang_tags and \"lang2\" in lang_tags:\n",
    "#         # find the dominant language (lang1=eng, lang2=spa)\n",
    "#         mlang = most_frequent_element(lang_tags)\n",
    "#         if mlang == \"lang1\":\n",
    "#             ner_results.append(\n",
    "#                 tag_eng_sent(model_eng=model_eng, corpus=corpus, sent_idx=i)\n",
    "#             )\n",
    "#         else:\n",
    "#             ner_results.append(\n",
    "#                 tag_spa_sent(model_spa=model_spa, corpus=corpus, sent_idx=i)\n",
    "#             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 33611/33611 [03:53<00:00, 143.97it/s]\n"
     ]
    }
   ],
   "source": [
    "def most_frequent_element(lst):\n",
    "    most_frequent = max(set(lst), key=lst.count)\n",
    "\n",
    "    return most_frequent\n",
    "\n",
    "\n",
    "ner_results_cs = []\n",
    "ner_results_noncs = []\n",
    "for i in tqdm(range(len(corpus)), desc=\"Processing\"):\n",
    "    lang_tags = list(corpus[i][\"lang\"])\n",
    "    if \"lang1\" in lang_tags and \"lang2\" in lang_tags:\n",
    "        # find the dominant language (lang1=eng, lang2=spa)\n",
    "        mlang = most_frequent_element(lang_tags)\n",
    "        if mlang == \"lang1\":\n",
    "            ner_results_cs.append(\n",
    "                tag_eng_sent(model_eng=model_eng, corpus=corpus, sent_idx=i)\n",
    "            )\n",
    "        else:\n",
    "            ner_results_cs.append(\n",
    "                tag_spa_sent(model_spa=model_spa, corpus=corpus, sent_idx=i)\n",
    "            )\n",
    "    else:\n",
    "        mlang = most_frequent_element(lang_tags)\n",
    "        if mlang == \"lang1\":\n",
    "            ner_results_noncs.append(\n",
    "                tag_eng_sent(model_eng=model_eng, corpus=corpus, sent_idx=i)\n",
    "            )\n",
    "        else:\n",
    "            ner_results_noncs.append(\n",
    "                tag_spa_sent(model_spa=model_spa, corpus=corpus, sent_idx=i)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix for NER results of monolingual sentences:\n",
      "               Predicted non-NE  Predicted NE\n",
      "Actual non-NE            221529         41730\n",
      "Actual NE                  2198          4470\n",
      "accuracy score for NER results of monolingual sentences: 0.8372597035494782\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "gold = np.array(list(itertools.chain(*[sent[\"true_ne\"] for sent in ner_results_noncs])))\n",
    "pred = np.array(\n",
    "    list(itertools.chain(*[sent[\"spacy_ne\"] for sent in ner_results_noncs]))\n",
    ")\n",
    "\n",
    "# create the confusion matrix\n",
    "cfm = confusion_matrix(gold, pred)\n",
    "# reshape the confusion matrix to a 2x2 matrix\n",
    "cfm = cfm.reshape((2, 2))\n",
    "\n",
    "# create a pandas DataFrame from the confusion matrix\n",
    "df_cfm = pd.DataFrame(\n",
    "    cfm,\n",
    "    index=[\"Actual non-NE\", \"Actual NE\"],\n",
    "    columns=[\"Predicted non-NE\", \"Predicted NE\"],\n",
    ")\n",
    "print(f\"confusion matrix for NER results of monolingual sentences:\\n{df_cfm}\")\n",
    "\n",
    "# get predictions accuracy scores\n",
    "acc = accuracy_score(gold, pred)\n",
    "print(f\"accuracy score for NER results of monolingual sentences: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_l1 = []  # gold NE tags of tokens of matrix language\n",
    "pred_l1 = []  # predicted NE tags of tokens of matrix language\n",
    "gold_l2 = []  # gold NE tags of tokens of embedded language\n",
    "pred_l2 = []  # predicted NE tags of tokens of embedded language\n",
    "\n",
    "for i in range(len(ner_results_cs)):\n",
    "    if ner_results_cs[i][\"mlang\"] == \"eng\":\n",
    "        # retrieve indices of tokens of matrix language == English\n",
    "        idx_l1 = [\n",
    "            idx for idx, item in enumerate(ner_results_cs[i][\"lang\"]) if item == \"lang1\"\n",
    "        ]\n",
    "        # get gold and spaCy NE tags and add to overall list\n",
    "        g_l1 = [ner_results_cs[i][\"true_ne\"][idx] for idx in idx_l1]\n",
    "        p_l1 = [ner_results_cs[i][\"spacy_ne\"][idx] for idx in idx_l1]\n",
    "        gold_l1.append(g_l1)\n",
    "        pred_l1.append(p_l1)\n",
    "\n",
    "        # do the same for tokens of embedded language == Spanish\n",
    "        idx_l2 = [\n",
    "            idx for idx, item in enumerate(ner_results_cs[i][\"lang\"]) if item == \"lang2\"\n",
    "        ]\n",
    "        g_l2 = [ner_results_cs[i][\"true_ne\"][idx] for idx in idx_l2]\n",
    "        p_l2 = [ner_results_cs[i][\"spacy_ne\"][idx] for idx in idx_l2]\n",
    "        gold_l2.append(g_l2)\n",
    "        pred_l2.append(p_l2)\n",
    "\n",
    "    elif ner_results_cs[i][\"mlang\"] == \"spa\":\n",
    "        # retrieve indices of tokens of matrix language == Spanish\n",
    "        idx_l1 = [\n",
    "            idx for idx, item in enumerate(ner_results_cs[i][\"lang\"]) if item == \"lang2\"\n",
    "        ]\n",
    "        # get gold and spaCy NE tags and add to overall list\n",
    "        g_l1 = [ner_results_cs[i][\"true_ne\"][idx] for idx in idx_l1]\n",
    "        p_l1 = [ner_results_cs[i][\"spacy_ne\"][idx] for idx in idx_l1]\n",
    "        gold_l1.append(g_l1)\n",
    "        pred_l1.append(p_l1)\n",
    "\n",
    "        # do the same for tokens of embedded language == English\n",
    "        idx_l2 = [\n",
    "            idx for idx, item in enumerate(ner_results_cs[i][\"lang\"]) if item == \"lang1\"\n",
    "        ]\n",
    "        g_l2 = [ner_results_cs[i][\"true_ne\"][idx] for idx in idx_l2]\n",
    "        p_l2 = [ner_results_cs[i][\"spacy_ne\"][idx] for idx in idx_l2]\n",
    "        gold_l2.append(g_l2)\n",
    "        pred_l2.append(p_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix for NER results of L1 tokens in code-mixed sentences:\n",
      "               Predicted non-NE  Predicted NE\n",
      "Actual non-NE             68521          9604\n",
      "Actual NE                   435           434\n",
      "accuracy score for NER results of L1 tokens in code-mixed sentences: 0.8729143985619161\n"
     ]
    }
   ],
   "source": [
    "gold_l1 = np.array(list(itertools.chain(*gold_l1)))\n",
    "pred_l1 = np.array(list(itertools.chain(*pred_l1)))\n",
    "\n",
    "# create the confusion matrix\n",
    "cfm = confusion_matrix(gold_l1, pred_l1)\n",
    "# reshape the confusion matrix to a 2x2 matrix\n",
    "cfm = cfm.reshape((2, 2))\n",
    "\n",
    "# create a pandas DataFrame from the confusion matrix\n",
    "df_cfm = pd.DataFrame(\n",
    "    cfm,\n",
    "    index=[\"Actual non-NE\", \"Actual NE\"],\n",
    "    columns=[\"Predicted non-NE\", \"Predicted NE\"],\n",
    ")\n",
    "print(f\"confusion matrix for NER results of L1 tokens in code-mixed sentences:\\n{df_cfm}\")\n",
    "\n",
    "# get predictions accuracy scores\n",
    "acc = accuracy_score(gold_l1, pred_l1)\n",
    "print(f\"accuracy score for NER results of L1 tokens in code-mixed sentences: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix for NER results of L2 tokens in code-mixed sentences:\n",
      "               Predicted non-NE  Predicted NE\n",
      "Actual non-NE             10710          6668\n",
      "Actual NE                   337           760\n",
      "accuracy score for NER results of L2 tokens in code-mixed sentences: 0.6208389715832205\n"
     ]
    }
   ],
   "source": [
    "gold_l2 = np.array(list(itertools.chain(*gold_l2)))\n",
    "pred_l2 = np.array(list(itertools.chain(*pred_l2)))\n",
    "\n",
    "# create the confusion matrix\n",
    "cfm = confusion_matrix(gold_l2, pred_l2)\n",
    "# reshape the confusion matrix to a 2x2 matrix\n",
    "cfm = cfm.reshape((2, 2))\n",
    "\n",
    "# create a pandas DataFrame from the confusion matrix\n",
    "df_cfm = pd.DataFrame(\n",
    "    cfm,\n",
    "    index=[\"Actual non-NE\", \"Actual NE\"],\n",
    "    columns=[\"Predicted non-NE\", \"Predicted NE\"],\n",
    ")\n",
    "print(f\"confusion matrix for NER results of L2 tokens in code-mixed sentences:\\n{df_cfm}\")\n",
    "\n",
    "# get predictions accuracy scores\n",
    "acc = accuracy_score(gold_l2, pred_l2)\n",
    "print(f\"accuracy score for NER results of L2 tokens in code-mixed sentences: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis 1\n",
    "\n",
    "How many inserted normal non-NE L2 words are falsely tagged as named entities?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_word_idxs: list of indices of inserted L2 tokens that are not NEs in each sentence\n",
    "target_word_idxs = []\n",
    "for result in ner_results_cs:\n",
    "    if result[\"mlang\"] == \"eng\":\n",
    "        # get CS Spanish token index\n",
    "        cs_idx = [i for i in range(len(result[\"lang\"])) if result[\"lang\"][i] == \"lang2\"]\n",
    "        # remove CS Spanish tokens that are actually NEs\n",
    "        cs_ne_idx = [idx for idx in cs_idx if result[\"true_ne\"][idx] == \"O\"]\n",
    "        target_word_idxs.append(cs_ne_idx)\n",
    "    elif result[\"mlang\"] == \"spa\":\n",
    "        # get CS English token index\n",
    "        cs_idx = [i for i in range(len(result[\"lang\"])) if result[\"lang\"][i] == \"lang1\"]\n",
    "        # remove CS English tokens that are actually NEs\n",
    "        cs_ne_idx = [idx for idx in cs_idx if result[\"true_ne\"][idx] == \"O\"]\n",
    "        target_word_idxs.append(cs_ne_idx)\n",
    "\n",
    "cs_fauxne = []  # [(CS tokens count, CS tokens tagged as NE count) of sent_1, ...]\n",
    "# get from spaCy falsely tagged inserted L2 tokens\n",
    "for i in range(len(target_word_idxs)):\n",
    "    if len(target_word_idxs[i]) > 0:\n",
    "        cs_count = len(target_word_idxs[i])\n",
    "        cs_as_ne_count = len(\n",
    "            [j for j in target_word_idxs[i] if ner_results_cs[i][\"spacy_ne\"][j] != \"O\"]\n",
    "        )\n",
    "        cs_fauxne.append((cs_count, cs_as_ne_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38370353320290024\n"
     ]
    }
   ],
   "source": [
    "all_cs_count = sum(t[0] for t in cs_fauxne)\n",
    "all_cs_as_ne_count = sum(t[1] for t in cs_fauxne)\n",
    "\n",
    "print(all_cs_as_ne_count / all_cs_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis 2\n",
    "\n",
    "How many falsely tagged tokens are actually normal inserted non-NE L2 words?\n",
    "\n",
    "Namely: How many error are caused by code-switching?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_word_idxs: list of indices of falsely tagged tokens by spaCy\n",
    "target_word_idxs = []\n",
    "for result in ner_results:\n",
    "    spacy_wrong_ne_idx = [\n",
    "        i\n",
    "        for i, (elem1, elem2) in enumerate(zip(result[\"spacy_ne\"], result[\"true_ne\"]))\n",
    "        if elem1 != elem2\n",
    "    ]\n",
    "    target_word_idxs.append(spacy_wrong_ne_idx)\n",
    "\n",
    "fauxne_at_cs = (\n",
    "    []\n",
    ")  # [(falsely tagged NE count, error on CS position count) of sent_1, ...]\n",
    "for i in range(len(target_word_idxs)):\n",
    "    if len(target_word_idxs[i]) > 0:\n",
    "        fauxne_count = len(target_word_idxs[i])\n",
    "        sentence = ner_results_cs[i]\n",
    "\n",
    "        if sentence[\"mlang\"] == \"eng\":\n",
    "            fauxne_at_cs_count = len(\n",
    "                [j for j in target_word_idxs[i] if sentence[\"lang\"][j] == \"lang2\"]\n",
    "            )\n",
    "        elif sentence[\"mlang\"] == \"spa\":\n",
    "            fauxne_at_cs_count = len(\n",
    "                [j for j in target_word_idxs[i] if sentence[\"lang\"][j] == \"lang1\"]\n",
    "            )\n",
    "        fauxne_at_cs.append((fauxne_count, fauxne_at_cs_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29552324744494024\n"
     ]
    }
   ],
   "source": [
    "all_fauxne_count = sum(t[0] for t in fauxne_at_cs)\n",
    "all_fauxne_at_cs_count = sum(t[1] for t in fauxne_at_cs)\n",
    "\n",
    "print(all_fauxne_at_cs_count / all_fauxne_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis 3\n",
    "\n",
    "How many inserted L2 tokens that are actually NEs are correctly identified as NE by L1 model?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_word_idxs: list of indices of inserted L2 words that are NEs by gold standard\n",
    "target_word_idxs = []\n",
    "for result in ner_results_cs:\n",
    "    if result[\"mlang\"] == \"eng\":\n",
    "        # get CS Spanish token index\n",
    "        cs_idx = [i for i in range(len(result[\"lang\"])) if result[\"lang\"][i] == \"lang2\"]\n",
    "        # keep CS Spanish tokens that are actually NEs\n",
    "        cs_ne_idx = [idx for idx in cs_idx if result[\"true_ne\"][idx] != \"O\"]\n",
    "        target_word_idxs.append(cs_ne_idx)\n",
    "    elif result[\"mlang\"] == \"spa\":\n",
    "        # get CS English token index\n",
    "        cs_idx = [i for i in range(len(result[\"lang\"])) if result[\"lang\"][i] == \"lang1\"]\n",
    "        # keep CS English tokens that are actually NEs\n",
    "        cs_ne_idx = [idx for idx in cs_idx if result[\"true_ne\"][idx] != \"O\"]\n",
    "        target_word_idxs.append(cs_ne_idx)\n",
    "\n",
    "csne_as_ne = []  # [(L2 tokens = NE count, NE-L2 tokens as NE count) of sent_1, ...]\n",
    "for i in range(len(ner_results_cs)):\n",
    "    if len(target_word_idxs[i]) > 0:\n",
    "        l2ne_count = len(target_word_idxs[i])\n",
    "        l2ne_as_ne_count = len(\n",
    "            [\n",
    "                j\n",
    "                for j in target_word_idxs[i]\n",
    "                if ner_results_cs[i][\"spacy_ne\"][j] == \"Yes\"\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        csne_as_ne.append((l2ne_count, l2ne_as_ne_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6927985414767548\n"
     ]
    }
   ],
   "source": [
    "all_l2ne_count = sum(t[0] for t in csne_as_ne)\n",
    "all_l2ne_as_ne_count = sum(t[1] for t in csne_as_ne)\n",
    "\n",
    "print(all_l2ne_as_ne_count / all_l2ne_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760\n"
     ]
    }
   ],
   "source": [
    "# how many inserted L2 tokens are also NEs\n",
    "print(all_l2ne_as_ne_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CompMod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
