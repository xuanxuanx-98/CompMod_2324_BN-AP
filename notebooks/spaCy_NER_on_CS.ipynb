{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spaCy Performance on Named Entity Recognition with Code-Mixed Data\n",
    "\n",
    "In this notebook we examine the multi-functional model spaCy's performances on named entity recognition (NER) tasks, when the data are multilingual. More specifically, we will be focusing on code-mixing (code-switched) data, where the vocabulary of two different languages are used interchangeably in one sentence.\n",
    "\n",
    "#### Data Source\n",
    "\n",
    "The data comes from Computational Approaches to Linguistic Code-Switching (CALCS), which are openly accessible through [LinCE Benchmark](https://ritual.uh.edu/lince/datasets). The specific subset used in this research is the train set in Spanish - English (SPA - ENG) from CALCS Shared Task 2018. The details of the structures of the data will be provides in the first section.\n",
    "\n",
    "#### Sentence Annotation\n",
    "\n",
    "Since spaCy models are usually built on monolingual data, the choice of which language specific model should be used to annotate the current sentence needs to be made based on individual cases. The general pipline goes as follows: \n",
    "\n",
    "1) Determine the matrix language (L1) of the sentence;\n",
    "2) Choose the spaCy model for L1 to annotate the whole sentence, in which tokens of another language (L2) are possibly inserted;\n",
    "3) Retrieve named entity recognition results from [Linguistic Features](https://spacy.io/usage/linguistic-features) built in spaCy standard pipeline;\n",
    "\n",
    "#### Performances Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xuanxuanx/Python/venvs/CompMod/lib64/python3.11/site-packages/torch/cuda/__init__.py:611: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in file\n",
    "file_path = \"../data/train.conll\"\n",
    "\n",
    "# empty list to store DataFrames for each sentence\n",
    "corpus = []\n",
    "\n",
    "# read the CoNLL-U file line by line\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "    current_sentence = []\n",
    "    columns = [\"word\", \"lang\", \"entity_type\"]\n",
    "    for line in lines:\n",
    "        if line.startswith(\"# sent_enum\"):\n",
    "            # if a new sentence begins, process the current one\n",
    "            if current_sentence:\n",
    "                df = pd.DataFrame(current_sentence, columns=columns)\n",
    "                corpus.append(df)\n",
    "                current_sentence = []\n",
    "        else:\n",
    "            # append each line to the current sentence\n",
    "            current_sentence.append(line.strip().split(\"\\t\"))\n",
    "\n",
    "# last sentence in the file\n",
    "if current_sentence:\n",
    "    df = pd.DataFrame(current_sentence, columns=columns)\n",
    "    corpus.append(df)\n",
    "# each sentence cann now be called by corpus[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load spaCy model for both L1 and L2\n",
    "model_eng = spacy.load(\"en_core_web_trf\")\n",
    "model_spa = spacy.load(\"es_dep_news_trf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_eng_sent(model_eng, corpus, sent_idx):\n",
    "    \"\"\"tag a sentence with English as L1\n",
    "    return a dictionary with language tags, gold NE tags and spacy NER results\"\"\"\n",
    "    sent_df = corpus[sent_idx][:-1]  # remove last row resulted by CoNLL-U seperator\n",
    "\n",
    "    # extract all pre-processed tokens to a list\n",
    "    gold_tokens = list(sent_df[\"word\"])\n",
    "    # regularize gold NER tags, save to list\n",
    "    gold_tags = [\"Yes\" if tag != \"O\" else \"O\" for tag in list(sent_df[\"entity_type\"])]\n",
    "    # also save language tags\n",
    "    gold_langs = list(sent_df[\"lang\"])\n",
    "\n",
    "    sentence_text = sent_df[\"word\"].str.cat(sep=\" \")\n",
    "    doc = model_eng(sentence_text)\n",
    "    nes = [i.text for i in doc.ents]\n",
    "    # flat the nes tokens\n",
    "    nes_tokens = [\n",
    "        item for sublist in [item.split() for item in nes] for item in sublist\n",
    "    ]\n",
    "\n",
    "    if len(nes_tokens) == 0:  # check if spaCy found any NE\n",
    "        spacy_tags = [\"O\"] * len(sent_df)\n",
    "    else:\n",
    "        spacy_tags = []  # list to store spaCy NER results\n",
    "        for token in gold_tokens:\n",
    "            if len(nes_tokens) != 0:\n",
    "                if token in nes_tokens[0] or nes_tokens[0] in token:\n",
    "                    spacy_tags.append(\"Yes\")\n",
    "                    nes_tokens = nes_tokens[1:]\n",
    "                else:\n",
    "                    spacy_tags.append(\"O\")\n",
    "            else:\n",
    "                spacy_tags.append(\"O\")\n",
    "\n",
    "    results = {\n",
    "        \"mlang\": \"eng\",\n",
    "        \"lang\": gold_langs,\n",
    "        \"true_ne\": gold_tags,\n",
    "        \"spacy_ne\": spacy_tags\n",
    "    }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_spa_sent(model_spa, corpus, sent_idx):\n",
    "    \"\"\"tag a sentence with English as L1\n",
    "    return a dictionary with language tags, gold NE tags and spacy NER results\"\"\"\n",
    "    sent_df = corpus[sent_idx][:-1]  # remove last row resulted by CoNLL-U seperator\n",
    "\n",
    "    # extract all pre-processed tokens to a list\n",
    "    gold_tokens = list(sent_df[\"word\"])\n",
    "    # regularize gold NER tags, save to list\n",
    "    gold_tags = [\"Yes\" if tag != \"O\" else \"O\" for tag in list(sent_df[\"entity_type\"])]\n",
    "    # also save language tags\n",
    "    gold_langs = list(sent_df[\"lang\"])\n",
    "\n",
    "    sentence_text = sent_df[\"word\"].str.cat(sep=\" \")\n",
    "    doc = model_spa(sentence_text)\n",
    "    nes = [i.text for i in doc.ents]\n",
    "    # flat the nes tokens\n",
    "    nes_tokens = [\n",
    "        item for sublist in [item.split() for item in nes] for item in sublist\n",
    "    ]\n",
    "\n",
    "    if len(nes_tokens) == 0:  # check if spaCy found any NE\n",
    "        spacy_tags = [\"O\"] * len(sent_df)\n",
    "    else:\n",
    "        spacy_tags = []  # list to store spaCy NER results\n",
    "        for token in gold_tokens:\n",
    "            if len(nes_tokens) != 0:\n",
    "                if token in nes_tokens[0] or nes_tokens[0] in token:\n",
    "                    spacy_tags.append(\"Yes\")\n",
    "                    nes_tokens = nes_tokens[1:]\n",
    "                else:\n",
    "                    spacy_tags.append(\"O\")\n",
    "            else:\n",
    "                spacy_tags.append(\"O\")\n",
    "\n",
    "    results = {\n",
    "        \"mlang\": \"spa\",\n",
    "        \"lang\": gold_langs,\n",
    "        \"true_ne\": gold_tags,\n",
    "        \"spacy_ne\": spacy_tags\n",
    "    }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/33611 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|â–Ž         | 1072/33611 [00:26<13:10, 41.18it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m     ner_results\u001b[38;5;241m.\u001b[39mappend(tag_eng_sent(model_eng\u001b[38;5;241m=\u001b[39mmodel_eng, corpus\u001b[38;5;241m=\u001b[39mcorpus, sent_idx\u001b[38;5;241m=\u001b[39mi))\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 15\u001b[0m     ner_results\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtag_spa_sent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_spa\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_spa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msent_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[6], line 14\u001b[0m, in \u001b[0;36mtag_spa_sent\u001b[0;34m(model_spa, corpus, sent_idx)\u001b[0m\n\u001b[1;32m     11\u001b[0m gold_langs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(sent_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlang\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     13\u001b[0m sentence_text \u001b[38;5;241m=\u001b[39m sent_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcat(sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m doc \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_spa\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m nes \u001b[38;5;241m=\u001b[39m [i\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m doc\u001b[38;5;241m.\u001b[39ments]\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# flat the nes tokens\u001b[39;00m\n",
      "File \u001b[0;32m~/Python/venvs/CompMod/lib64/python3.11/site-packages/spacy/language.py:1049\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     error_handler \u001b[38;5;241m=\u001b[39m proc\u001b[38;5;241m.\u001b[39mget_error_handler()\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1049\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mproc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcomponent_cfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1051\u001b[0m     \u001b[38;5;66;03m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE109\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/Python/venvs/CompMod/lib64/python3.11/site-packages/spacy/pipeline/trainable_pipe.pyx:52\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Python/venvs/CompMod/lib64/python3.11/site-packages/spacy_curated_transformers/pipeline/transformer.py:242\u001b[0m, in \u001b[0;36mCuratedTransformer.predict\u001b[0;34m(self, docs)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;66;03m# To ensure that the model's internal state is always consistent with the pipe's.\u001b[39;00m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_model_all_layer_outputs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_layer_outputs)\n\u001b[0;32m--> 242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Python/venvs/CompMod/lib64/python3.11/site-packages/thinc/model.py:334\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m OutT:\n\u001b[1;32m    331\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;124;03m    only the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Python/venvs/CompMod/lib64/python3.11/site-packages/spacy_curated_transformers/models/architectures.py:651\u001b[0m, in \u001b[0;36mtransformer_model_forward\u001b[0;34m(model, docs, is_train)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransformer_model_forward\u001b[39m(\n\u001b[1;32m    649\u001b[0m     model: TransformerModelT, docs: TransformerInT, is_train: \u001b[38;5;28mbool\u001b[39m\n\u001b[1;32m    650\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[TransformerOutT, TransformerBackpropT]:\n\u001b[0;32m--> 651\u001b[0m     Y, backprop_layer \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    653\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackprop\u001b[39m(dY):\n\u001b[1;32m    654\u001b[0m         backprop_layer(dY)\n",
      "File \u001b[0;32m~/Python/venvs/CompMod/lib64/python3.11/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Python/venvs/CompMod/lib64/python3.11/site-packages/spacy_curated_transformers/models/with_non_ws_tokens.py:72\u001b[0m, in \u001b[0;36mwith_non_ws_tokens_forward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     70\u001b[0m inner: Model[Tok2PiecesInT, WsTokenAdapterOutT] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     71\u001b[0m tokens, ws_counts \u001b[38;5;241m=\u001b[39m _filter_tokens(X)\n\u001b[0;32m---> 72\u001b[0m Y_no_ws, backprop_no_ws \u001b[38;5;241m=\u001b[39m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Note: we modify the model outputs in-place. Since we are wrapping the\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# model, there should be no other consumers. Not sure yet if the same\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# applies to the gradient (e.g. consider summing two encoders of the\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# same width downstream.)\u001b[39;00m\n\u001b[1;32m     79\u001b[0m alignments \u001b[38;5;241m=\u001b[39m _create_alignments(model, Y_no_ws, ws_counts)\n",
      "File \u001b[0;32m~/Python/venvs/CompMod/lib64/python3.11/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Python/venvs/CompMod/lib64/python3.11/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[0;32m~/Python/venvs/CompMod/lib64/python3.11/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Python/venvs/CompMod/lib64/python3.11/site-packages/spacy_curated_transformers/models/with_strided_spans.py:108\u001b[0m, in \u001b[0;36mwith_strided_spans_forward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m    106\u001b[0m outputs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m _split_spans(spans, batch_size):\n\u001b[0;32m--> 108\u001b[0m     output, bp \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTorchTransformerInT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, TransformerModelOutput):\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    111\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m received an unexpected input of type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(output)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    112\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt can only wrap/be chained with models whose outputs are of type  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    113\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`TransformerModelOutput` (in almost all cases, models of type `TorchTransformerModelT`)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    114\u001b[0m         )\n",
      "File \u001b[0;32m~/Python/venvs/CompMod/lib64/python3.11/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Python/venvs/CompMod/lib64/python3.11/site-packages/thinc/layers/pytorchwrapper.py:225\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m    222\u001b[0m convert_outputs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mattrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    224\u001b[0m Xtorch, get_dX \u001b[38;5;241m=\u001b[39m convert_inputs(model, X, is_train)\n\u001b[0;32m--> 225\u001b[0m Ytorch, torch_backprop \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshims\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtorch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m Y, get_dYtorch \u001b[38;5;241m=\u001b[39m convert_outputs(model, (X, Ytorch), is_train)\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackprop\u001b[39m(dY: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n",
      "File \u001b[0;32m~/Python/venvs/CompMod/lib64/python3.11/site-packages/thinc/shims/pytorch.py:97\u001b[0m, in \u001b[0;36mPyTorchShim.__call__\u001b[0;34m(self, inputs, is_train)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbegin_update(inputs)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mlambda\u001b[39;00m a: \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n",
      "File \u001b[0;32m~/Python/venvs/CompMod/lib64/python3.11/site-packages/thinc/shims/pytorch.py:115\u001b[0m, in \u001b[0;36mPyTorchShim.predict\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mixed_precision):\n\u001b[0;32m--> 115\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/Python/venvs/CompMod/lib64/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Python/venvs/CompMod/lib64/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Python/venvs/CompMod/lib64/python3.11/site-packages/curated_transformers/models/curated_transformer.py:37\u001b[0m, in \u001b[0;36mCuratedTransformer.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     29\u001b[0m     input_ids: Tensor,\n\u001b[1;32m     30\u001b[0m     attention_mask: Optional[AttentionMask] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     31\u001b[0m     token_type_ids: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     32\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PyTorchTransformerOutput:\n\u001b[1;32m     33\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m    Shapes:\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m        input_ids, attention_mask, token_type_ids - (batch, seq_len)\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurated_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Python/venvs/CompMod/lib64/python3.11/site-packages/curated_transformers/models/bert/encoder.py:52\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids)\u001b[0m\n\u001b[1;32m     50\u001b[0m layer_outputs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 52\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     layer_outputs\u001b[38;5;241m.\u001b[39mappend(layer_output)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m PyTorchTransformerOutput(\n\u001b[1;32m     56\u001b[0m     embedding_output\u001b[38;5;241m=\u001b[39membeddings, layer_hidden_states\u001b[38;5;241m=\u001b[39mlayer_outputs\n\u001b[1;32m     57\u001b[0m )\n",
      "File \u001b[0;32m~/Python/venvs/CompMod/lib64/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Python/venvs/CompMod/lib64/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Python/venvs/CompMod/lib64/python3.11/site-packages/curated_transformers/models/bert/layer.py:133\u001b[0m, in \u001b[0;36mBertEncoderLayer.forward\u001b[0;34m(self, x, attn_mask)\u001b[0m\n\u001b[1;32m    130\u001b[0m attn_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_output_dropout(attn_out)\n\u001b[1;32m    131\u001b[0m attn_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_output_layernorm(x \u001b[38;5;241m+\u001b[39m attn_out)\n\u001b[0;32m--> 133\u001b[0m ffn_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mffn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_out\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m ffn_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mffn_output_dropout(ffn_out)\n\u001b[1;32m    135\u001b[0m ffn_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mffn_output_layernorm(attn_out \u001b[38;5;241m+\u001b[39m ffn_out)\n",
      "File \u001b[0;32m~/Python/venvs/CompMod/lib64/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Python/venvs/CompMod/lib64/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Python/venvs/CompMod/lib64/python3.11/site-packages/curated_transformers/models/bert/layer.py:102\u001b[0m, in \u001b[0;36mBertFeedForward.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    100\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(x)\n\u001b[1;32m    101\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(out)\n\u001b[0;32m--> 102\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/Python/venvs/CompMod/lib64/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Python/venvs/CompMod/lib64/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Python/venvs/CompMod/lib64/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def most_frequent_element(lst):\n",
    "    most_frequent = max(set(lst), key=lst.count)\n",
    "\n",
    "    return most_frequent\n",
    "\n",
    "\n",
    "ner_results = []\n",
    "for i in tqdm(range(len(corpus)), desc=\"Processing\"):\n",
    "    # find the dominant language (lang1=eng, lang2=spa)\n",
    "    lang_tags = list(corpus[i][\"lang\"])\n",
    "    mlang = most_frequent_element(lang_tags)\n",
    "    if mlang == \"lang1\":\n",
    "        ner_results.append(tag_eng_sent(model_eng=model_eng, corpus=corpus, sent_idx=i))\n",
    "    else:\n",
    "        ner_results.append(tag_spa_sent(model_spa=model_spa, corpus=corpus, sent_idx=i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis 1\n",
    "\n",
    "How many inserted normal non-NE L2 words are falsely tagged as named entities? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_word_idxs: list of indices of inserted L2 tokens that are not NEs in each sentence\n",
    "target_word_idxs = []\n",
    "for result in ner_results:\n",
    "    if result[\"mlang\"] == \"eng\":\n",
    "        # get CS Spanish token index\n",
    "        cs_idx = [i for i in range(len(result[\"lang\"])) if result[\"lang\"][i] == \"lang2\"]\n",
    "        # remove CS Spanish tokens that are actually NEs\n",
    "        cs_ne_idx = [idx for idx in cs_idx if result[\"true_ne\"][idx] == \"O\"]\n",
    "        target_word_idxs.append(cs_ne_idx)\n",
    "    elif result[\"mlang\"] == \"spa\":\n",
    "        # get CS English token index\n",
    "        cs_idx = [i for i in range(len(result[\"lang\"])) if result[\"lang\"][i] == \"lang1\"]\n",
    "        # remove CS English tokens that are actually NEs\n",
    "        cs_ne_idx = [idx for idx in cs_idx if result[\"true_ne\"][idx] == \"O\"]\n",
    "        target_word_idxs.append(cs_ne_idx)\n",
    "\n",
    "cs_fauxne = []  # [(CS tokens count, CS tokens tagged as NE count) of sent_1, ...]\n",
    "# get from spaCy falsely tagged inserted L2 tokens\n",
    "for i in range(len(target_word_idxs)):\n",
    "    if len(target_word_idxs[i]) > 0:\n",
    "        cs_count = len(target_word_idxs[i])\n",
    "        cs_as_ne_count = len(\n",
    "            [j for j in target_word_idxs[i] if ner_results[i][\"spacy_ne\"][j] != \"O\"]\n",
    "        )\n",
    "        cs_fauxne.append((cs_count, cs_as_ne_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4294302626711062"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cs_count = sum(t[0] for t in cs_fauxne)\n",
    "all_cs_as_ne_count = sum(t[1] for t in cs_fauxne)\n",
    "\n",
    "all_cs_as_ne_count / all_cs_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis 2\n",
    "\n",
    "How many falsely tagged tokens are actually normal inserted non-NE L2 words?\n",
    "\n",
    "Namely: How many error are caused by code-switching?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_word_idxs: list of indices of falsely tagged tokens by spaCy\n",
    "target_word_idxs = []\n",
    "for result in ner_results:\n",
    "    spacy_wrong_ne_idx = [\n",
    "        i\n",
    "        for i, (elem1, elem2) in enumerate(zip(result[\"spacy_ne\"], result[\"true_ne\"]))\n",
    "        if elem1 != elem2\n",
    "    ]\n",
    "    target_word_idxs.append(spacy_wrong_ne_idx)\n",
    "\n",
    "fauxne_at_cs = []  # [(falsely tagged NE count, error on CS position count) of sent_1, ...]\n",
    "for i in range(len(target_word_idxs)):\n",
    "    if len(target_word_idxs[i]) > 0:\n",
    "        fauxne_count = len(target_word_idxs[i])\n",
    "        sentence = ner_results[i]\n",
    "\n",
    "        if sentence[\"mlang\"] == \"eng\":\n",
    "            fauxne_at_cs_count = len([j for j in target_word_idxs[i] if sentence[\"lang\"][j] == \"lang2\"])\n",
    "        elif sentence[\"mlang\"] == \"spa\":\n",
    "            fauxne_at_cs_count = len([j for j in target_word_idxs[i] if sentence[\"lang\"][j] == \"lang1\"])\n",
    "        fauxne_at_cs.append((fauxne_count, fauxne_at_cs_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13780409502746666"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_fauxne_count = sum(t[0] for t in fauxne_at_cs)\n",
    "all_fauxne_at_cs_count = sum(t[1] for t in fauxne_at_cs)\n",
    "\n",
    "all_fauxne_at_cs_count / all_fauxne_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis 3\n",
    "\n",
    "How many inserted L2 tokens that are actually NEs are correctly identified as NE by L1 model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_word_idxs: list of indices of inserted L2 words that are NEs by gold standard\n",
    "target_word_idxs = []\n",
    "for result in ner_results:\n",
    "    if result[\"mlang\"] == \"eng\":\n",
    "        # get CS Spanish token index\n",
    "        cs_idx = [i for i in range(len(result[\"lang\"])) if result[\"lang\"][i] == \"lang2\"]\n",
    "        # keep CS Spanish tokens that are actually NEs\n",
    "        cs_ne_idx = [idx for idx in cs_idx if result[\"true_ne\"][idx] != \"O\"]\n",
    "        target_word_idxs.append(cs_ne_idx)\n",
    "    elif result[\"mlang\"] == \"spa\":\n",
    "        # get CS English token index\n",
    "        cs_idx = [i for i in range(len(result[\"lang\"])) if result[\"lang\"][i] == \"lang1\"]\n",
    "        # keep CS English tokens that are actually NEs\n",
    "        cs_ne_idx = [idx for idx in cs_idx if result[\"true_ne\"][idx] != \"O\"]\n",
    "        target_word_idxs.append(cs_ne_idx)\n",
    "\n",
    "csne_as_ne = []  # [(L2 tokens = NE count, NE-L2 tokens as NE count) of sent_1, ...]\n",
    "for i in range(len(ner_results)):\n",
    "    if len(target_word_idxs[i]) > 0:\n",
    "        l2ne_count = len(target_word_idxs[i])\n",
    "        l2ne_as_ne_count = len([j for j in target_word_idxs[i] if ner_results[i][\"spacy_ne\"][j] == \"Yes\"])\n",
    "\n",
    "        csne_as_ne.append((l2ne_count, l2ne_as_ne_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6963265306122449"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_l2ne_count = sum(t[0] for t in csne_as_ne)\n",
    "all_l2ne_as_ne_count = sum(t[1] for t in csne_as_ne)\n",
    "\n",
    "all_l2ne_as_ne_count / all_l2ne_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CompMod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
