{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xuanxuanx/Python/venvs/MultiV/lib64/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "\n",
    "import argparse\n",
    "from src.Dialects import AfricanAmericanVernacular\n",
    "from src.Dialects import NigerianDialect\n",
    "from src.Dialects import HongKongDialect\n",
    "from src.Dialects import ColloquialSingaporeDialect\n",
    "from src.Dialects import AfricanAmericanVernacular\n",
    "from src.Dialects import ColloquialSingaporeDialect\n",
    "from src.Dialects import IndianDialect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Davidson's Twitter data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./davidson_og_all.csv', sep=',', index_col=False)\n",
    "\n",
    "def transform_to_dialect(dialect,df,dialect_name):\n",
    "    sents = []  # {text: ..., rules: [...]}\n",
    "\n",
    "    for i in tqdm(range(1000), desc=\"Processing\"):\n",
    "        sent = df[\"tweet\"][i]  # load original sentece\n",
    "\n",
    "        sent_dict = {}\n",
    "        sent_dict[\"text\"] = dialect.convert_sae_to_dialect(sent)\n",
    "        sent_dict[\"rules\"] = list(set([i[\"type\"] for i in dialect.executed_rules.values()]))\n",
    "\n",
    "        sents.append(sent_dict)\n",
    "\n",
    "    with open(f'{dialect_name}.jsonl', 'w') as outfile:\n",
    "        for entry in sents:\n",
    "            json.dump(entry, outfile)\n",
    "            outfile.write('\\n')\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:14<00:00, 68.72it/s]\n",
      "Processing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:15<00:00, 64.76it/s]\n",
      "Processing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:27<00:00, 36.80it/s]\n",
      "Processing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:23<00:00, 42.64it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load and run AAVE transform module, save results\n",
    "aave = AfricanAmericanVernacular()\n",
    "transform_to_dialect(dialect=aave, df=df, dialect_name=\"aave\")\n",
    "\n",
    "# load and run Nigerian dialect transform module, save results\n",
    "ngd = NigerianDialect()\n",
    "transform_to_dialect(dialect=ngd, df=df, dialect_name=\"nigerianD\")\n",
    "\n",
    "# load and run HongKong dialect transform module, save results\n",
    "indd = IndianDialect()\n",
    "transform_to_dialect(dialect=indd, df=df, dialect_name=\"indianD\")\n",
    "\n",
    "# load and run Singlish dialect transform module, save results\n",
    "csgd = ColloquialSingaporeDialect()\n",
    "transform_to_dialect(dialect=csgd, df=df, dialect_name=\"singlish\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HateXplain Twitter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(f\"./hatexplain_original.json\").transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_dialect(dialect,df,dialect_name):\n",
    "    sents = []  # {text: ..., rules: [...]}\n",
    "\n",
    "    for i in tqdm(range(1000), desc=\"Processing\"):\n",
    "        sent = \" \".join(df[\"post_tokens\"][0])  # load original sentece\n",
    "\n",
    "        sent_dict = {}\n",
    "        sent_dict[\"text\"] = dialect.convert_sae_to_dialect(sent)\n",
    "        sent_dict[\"rules\"] = list(set([i[\"type\"] for i in dialect.executed_rules.values()]))\n",
    "\n",
    "        sents.append(sent_dict)\n",
    "\n",
    "    with open(f'{dialect_name}.jsonl', 'w') as outfile:\n",
    "        for entry in sents:\n",
    "            json.dump(entry, outfile)\n",
    "            outfile.write('\\n')\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i dont think im getting my baby them white 9 he has two white j and nikes not even touched\n",
      "we cannot continue calling ourselves feminists if the rights of all womxn arent addressed yes to a sexual offences public list but will a trans lesbian bisexual and queer womxn be able to enter their information on the reporting sheet gender forum\n",
      "nawt yall niggers ignoring me\n",
      "<user> i am bit confused coz chinese ppl can not access twitter thn how this ching chong using it i think he pakistani ðŸ¤” ðŸ¤” ðŸ¤”\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join(df[\"post_tokens\"][0]))\n",
    "print(\" \".join(df[\"post_tokens\"][1]))\n",
    "print(\" \".join(df[\"post_tokens\"][2]))\n",
    "print(\" \".join(df[\"post_tokens\"][3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:13<00:00, 71.70it/s]\n",
      "Processing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:11<00:00, 90.64it/s]\n",
      "Processing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:26<00:00, 38.04it/s]\n",
      "Processing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:29<00:00, 34.39it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load and run AAVE transform module, save results\n",
    "aave = AfricanAmericanVernacular()\n",
    "transform_to_dialect(dialect=aave, df=df, dialect_name=\"aave\")\n",
    "\n",
    "# load and run Nigerian dialect transform module, save results\n",
    "ngd = NigerianDialect()\n",
    "transform_to_dialect(dialect=ngd, df=df, dialect_name=\"nigerianD\")\n",
    "\n",
    "# load and run HongKong dialect transform module, save results\n",
    "indd = IndianDialect()\n",
    "transform_to_dialect(dialect=indd, df=df, dialect_name=\"indianD\")\n",
    "\n",
    "# load and run Singlish dialect transform module, save results\n",
    "csgd = ColloquialSingaporeDialect()\n",
    "transform_to_dialect(dialect=csgd, df=df, dialect_name=\"singlish\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BASE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
